{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install arviz\n",
    "!pip install pymc3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import seaborn as sns\n",
    "from pymc3 import math\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the files\n",
    "with open('blanka_inputs/c_no_punish.npy', 'rb') as f:\n",
    "    c_no_punish = np.load(f)\n",
    "\n",
    "with open('blanka_inputs/c_punish.npy', 'rb') as f:\n",
    "    c_punish = np.load(f)\n",
    "\n",
    "with open('blanka_inputs/c.npy', 'rb') as f:\n",
    "    c = np.load(f)\n",
    "\n",
    "with open('blanka_inputs/Ga_no_punish.npy', 'rb') as f:\n",
    "    Ga_no_punish = np.load(f)\n",
    "\n",
    "with open('blanka_inputs/Ga_punish.npy', 'rb') as f:\n",
    "    Ga_punish = np.load(f)\n",
    "\n",
    "with open('blanka_inputs/Ga.npy', 'rb') as f:\n",
    "    Ga = np.load(f)\n",
    "\n",
    "with open('blanka_inputs/Gc_no_punish.npy', 'rb') as f:\n",
    "    Gc_no_punish = np.load(f)\n",
    "\n",
    "with open('blanka_inputs/Gc_punish.npy', 'rb') as f:\n",
    "    Gc_punish = np.load(f)\n",
    "\n",
    "with open('blanka_inputs/Gc.npy', 'rb') as f:\n",
    "    Gc = np.load(f)\n",
    "\n",
    "with open('blanka_inputs/Gini.npy', 'rb') as f:\n",
    "    Gini = np.load(f)\n",
    "\n",
    "with open('blanka_inputs/c_choice_index.npy', 'rb') as f:\n",
    "    c_choice_index = np.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupSize = 4\n",
    "ntrials = 10\n",
    "pi = 1.4\n",
    "ntokens = 20\n",
    "ngroups = 244\n",
    "vals = np.arange(0,21,1) #possible values to contribute - from 0 to 20 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []                       \n",
    "for people in range(0,4):\n",
    "    for trials in range (0,10):\n",
    "        for group in range (0,244):\n",
    "            data.append([people, trials, group, c[people, trials, group,0]])\n",
    "            \n",
    "data = pd.DataFrame(data, columns=['people', 'trials', 'group', 'value'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ginni = pd.DataFrame(Gini,  columns=['gini'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ginni['group'] = Ginni.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = data.merge(Ginni, on='group', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idi = pd.Categorical(merged.people).codes\n",
    "groupi = pd.Categorical(merged.group).codes\n",
    "triali = pd.Categorical(merged.trials).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decay model\n",
    "\n",
    "with pm.Model() as decay_model:\n",
    "    beta0_c0 = pm.HalfNormal('beta0_c0', sigma =1)\n",
    "\n",
    "    betaGini_c0 = pm.Normal(' betaGini_c0', mu = 0, sigma = 1)\n",
    "\n",
    "    \n",
    "    beta0_gamma = pm.HalfNormal('beta0_gamma', sigma = 1)\n",
    "\n",
    "    betaGini_gamma = pm.Normal('betaGini_gamma', mu = 0, sigma = 1)\n",
    "\n",
    "\n",
    "    sigma_c = pm.Gamma('sigma_c', alpha = 1, beta = 1, shape = (4,244))\n",
    "    c_0 = pm.Deterministic('c_0', beta0_c0 + betaGini_c0 * Gini_unst[groupi] )\n",
    "    gamma = pm.Deterministic('gamma', beta0_gamma+ (betaGini_gamma* Gini_unst[groupi]))\n",
    "    mu_c = pm.Deterministic('mu_c',c_0[groupi] * pm.math.exp(-gamma[groupi] * merged.trials))\n",
    "    ind_c = pm.Normal('ind_c', mu = mu_c[groupi], sigma = sigma_c[idi, groupi], observed = merged.value, shape = (4, 244))\n",
    "    trace_1 = pm.sample(return_inferencedata = True, chains=1, random_seed = 88)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace_1, var_names = [' betaGini_c0', 'betaGini_gamma', 'beta0_c0', 'beta0_gamma', 'sigma_c', 'gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace_1, var_names = [' betaGini_c0', 'betaGini_gamma', 'beta0_c0', 'beta0_gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with decay_model:\n",
    "    ppc = pm.sample_posterior_predictive(\n",
    "        trace_1, random_seed=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_ppc(az.from_pymc3(posterior_predictive=ppc, model=decay_model));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THE CC MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardise Gini score for analysis - we need to do this because model is more complex and won't converge otherwise\n",
    "Gini_unst = Gini\n",
    "Gini = (Gini - np.average(Gini)) / (np.std(Gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano.tensor as tsr\n",
    "\n",
    "def probit_phi(x):\n",
    "    \"\"\" Probit transform assuming 0 mean and 1 sd \"\"\"\n",
    "    mu = 0\n",
    "    sd = 1\n",
    "    return 0.5 * (1 + tsr.erf((x - mu) / (sd * tsr.sqrt(2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gini1 = np.array([Gini,Gini,Gini,Gini])\n",
    "\n",
    "Trials1 = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "Trials1 = np.array([Trials1,Trials1,Trials1,Trials1]).T\n",
    "Trials1 = Trials1[:,:,None]\n",
    "Trials1.shape\n",
    "\n",
    "values = np.array([vals,vals,vals,vals]).T\n",
    "values = values[:,:,None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3.math import switch, lt\n",
    "Gb0 = c[:,0,:,0].flatten()\n",
    "Muc0 = np.array([Ga[0,:,0], Ga[0,:,0], Ga[0,:,0], Ga[0,:,0]]).flatten()\n",
    "\n",
    "with pm.Model() as CC_Gini:\n",
    "    #beta0_pbeta = 1\n",
    "    beta0_pbeta = pm.Normal('beta0_pbeta', mu = 0, sigma = 1)\n",
    "    #betaGini_pbeta = 1\n",
    "    betaGini_pbeta = pm.Normal('betaGini_pbeta', mu = 0, sigma = 1)\n",
    "    \n",
    "    #------------------------- Individual regression priors -------------------------------------------\n",
    "    mu_pbeta_probit = pm.Deterministic('mu_pbeta_probit', beta0_pbeta + (betaGini_pbeta*Gini1))\n",
    "    #mu_pbeta_probit = 1\n",
    "    sigma_pbeta = pm.Uniform('sigma_pbeta', 1, 100, shape = (4, 244)) #concentration parameter for reparameterised beta distribution\n",
    "    #sigma_pbeta = 1\n",
    "    # reparameterising beta prior for slope of beliefs/preferences  in CC model                                                                \n",
    "    mu_pbeta = probit_phi(mu_pbeta_probit) # probit descale - - mean for cond is lower than overall\n",
    "    # In the paper, the sigma is added; in the code it's multiplied; we are adding\n",
    "    shape1_pbeta = mu_pbeta+sigma_pbeta\n",
    "    shape2_pbeta = (1 - mu_pbeta)+sigma_pbeta\n",
    "\n",
    "    #------------------------- Model level priors ------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------------------                                                                     \n",
    "    #decay rate in weighting of beliefs about others - prefs dominate over time\n",
    "    lam = pm.Beta('lam', 1,1, shape = (4,244))                                                                    \n",
    "    #parameter weighting of beliefs about what others will contribute, relative to observed contribution     \n",
    "    gamma = pm.Beta('gamma', 1,1, shape = (4,244))                                                                         \n",
    "    #~ dunif(0,20) #intercept of linear model relating preferred contributions to possible contribution values\n",
    "    p0 = pm.Uniform('p0', 0,20, shape = (4,244))\n",
    "    #slope of linear model relating preferred contributions to possible contribution values                                                                     \n",
    "    pbeta = pm.Beta('pbeta', shape1_pbeta+1,shape2_pbeta+1, shape = (4,244)) # TODO: check for no +1                                                                    \n",
    "    \n",
    "    #vector of preferred contributions for each possible value - linear relationship\n",
    "    #pvals = pm.Deterministic('pvals', p0 + (pbeta * values)) # pvals[i, s, g]\n",
    "    pvals =  p0 + (pbeta * values)\n",
    "    \n",
    "    #assume beliefs about others on first trial is reflected in first contribution. Simplification for model.\n",
    "    #make a matrix with the shape of 4 , 10, 244\n",
    "    #Gb0 = c[:,0,:,0].flatten() imma put this outside the model\n",
    "    #initial weighting of beliefs about others contributions in choice of own contribution, relative to prefs\n",
    "    Om0 = pm.Beta('omega0', 1,1, shape = (4*244))\n",
    "    #Muc0 = np.array([Ga[0,:,0], Ga[0,:,0], Ga[0,:,0], Ga[0,:,0]]).flatten() -- putting this outside\n",
    "    Out0 = pm.Normal('Out0', Muc0,0.1, observed = merged[merged['trials']==0].value)\n",
    "    \n",
    "    \n",
    "    Gb = []\n",
    "    Om = []\n",
    "    Muc = []\n",
    "    Out = []\n",
    "\n",
    "    Om.append(Om0)\n",
    "    Gb.append(Gb0)\n",
    "    Muc.append(Muc0)\n",
    "    Out.append(Out0)\n",
    "    \n",
    "    for i in range(1,10):\n",
    "        datat = merged[merged['trials']==i]\n",
    "        sid = pd.Categorical(datat.people).codes\n",
    "        gid = pd.Categorical(datat.group).codes\n",
    "        Om.append(pm.Deterministic('omega'+str(i), Om[i-1]*(1-lam[sid,gid])))\n",
    "        # We chose to ceil Gb to avoid issues with pvals\n",
    "        Gb.append(pm.Deterministic('Gb'+str(i), Gb[i-1]*gamma[sid,gid]+(1-gamma[sid,gid] * Ga[i-1, gid,0])))\n",
    "        # Look at what you made me do.\n",
    "        Muc.append(Om[i]*Gb[i] + (1-Om[i])*pvals[\n",
    "            switch(lt(Gb[i], 1),0, switch(lt(Gb[i],2),1, switch(lt(Gb[i],3),2, switch(lt(Gb[i],4),3,\n",
    "            switch(lt(Gb[i],5),4, switch(lt(Gb[i],6),5,switch(lt(Gb[i],7),6,switch(lt(Gb[i],8),7,\n",
    "            switch(lt(Gb[i],9),8,switch(lt(Gb[i],10),9,switch(lt(Gb[i],11),10,switch(lt(Gb[i],12),11,\n",
    "            switch(lt(Gb[i],13),12,switch(lt(Gb[i],14),13,switch(lt(Gb[i],15),14,switch(lt(Gb[i],16),15,\n",
    "            switch(lt(Gb[i],17),16,switch(lt(Gb[i],18),17,switch(lt(Gb[i],19),18,switch(lt(Gb[i],20),19,20)\n",
    "            ))))))))))))))))))), sid,gid])\n",
    "        Out.append(pm.Normal('out'+str(i), Muc[i], 0.1, observed = merged[merged['trials']==i].value))\n",
    "    bad_trace = pm.sample(200, tune=400, return_inferencedata = True, chains=1, random_seed = 978)\n",
    "    #done = False\n",
    "    #seed = 0\n",
    "    #while not done:\n",
    "    #    try:\n",
    "    #        bad_trace = pm.sample(200, tune=400, return_inferencedata = True, chains=1, random_seed = seed)\n",
    "    #        done = True\n",
    "    #    except:\n",
    "    #        seed +=1\n",
    "            \n",
    "    #print(seed)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace_1, var_names = ['beta0_pbeta', 'betaGini_pbeta', 'mu_pbeta_probit', 'sigma_pbeta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.arange(0,976)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we keep getting an error and we don't know how to fix it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
